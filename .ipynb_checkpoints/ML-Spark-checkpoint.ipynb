{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "from pyspark.ml.feature import *\n",
    "# CountVectorizer, Tokenizer, RegexTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "### Load data from file\n",
    "Since our data is stored as a bz2 we can use a python library, bz2 to iterate through the compressed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'archived': False,\n",
       " u'author': u'YoungModern',\n",
       " u'author_flair_css_class': None,\n",
       " u'author_flair_text': None,\n",
       " u'body': u'Most of us have some family members like this. *Most* of my family is like this. ',\n",
       " u'controversiality': 0,\n",
       " u'created_utc': u'1420070400',\n",
       " u'distinguished': None,\n",
       " u'downs': 0,\n",
       " u'edited': False,\n",
       " u'gilded': 0,\n",
       " u'id': u'cnas8zv',\n",
       " u'link_id': u't3_2qyr1a',\n",
       " u'name': u't1_cnas8zv',\n",
       " u'parent_id': u't3_2qyr1a',\n",
       " u'retrieved_on': 1425124282,\n",
       " u'score': 14,\n",
       " u'score_hidden': False,\n",
       " u'subreddit': u'exmormon',\n",
       " u'subreddit_id': u't5_2r0gj',\n",
       " u'ups': 14}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load compressed file\n",
    "reddit_comments = bz2.BZ2File('RC_2015-01.bz2', \"r\")\n",
    "# Read first line and load as json\n",
    "json.loads(reddit_comments.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame object\n",
    "\n",
    "Load the first 1000 comments and create a Spark DataFrame. This DataFrame will be used to test the machine learning methods below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of comments retrieved: 1000\n",
      "Total number of comments with body not deleted: 935\n"
     ]
    }
   ],
   "source": [
    "reddit_comments = bz2.BZ2File('RC_2015-01.bz2', \"r\")\n",
    "\n",
    "# total number of lines to read\n",
    "N = 1000\n",
    "json_lines= []\n",
    "# this method is not memory efficient, will require a large list with full dataset\n",
    "for _ in range(0,N):\n",
    "    json_lines.append(reddit_comments.readline())\n",
    "\n",
    "# create \n",
    "commentRDD = sc.parallelize(json_lines)\n",
    "commentDF = spark.read.json(commentRDD)\n",
    "\n",
    "# remove comments that don't contain any body text\n",
    "commentDF = commentDF.filter(\"body != '[deleted]'\")\n",
    "\n",
    "print \"Total number of comments retrieved: %s\" % len(json_lines)\n",
    "print \"Total number of comments with body not deleted: %s\" % commentDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names of comment DataFrame:\n",
      "['archived', 'author', 'author_flair_css_class', 'author_flair_text', 'body', 'controversiality', 'created_utc', 'distinguished', 'downs', 'edited', 'gilded', 'id', 'link_id', 'name', 'parent_id', 'retrieved_on', 'score', 'score_hidden', 'subreddit', 'subreddit_id', 'ups']\n"
     ]
    }
   ],
   "source": [
    "print \"Column names of comment DataFrame:\"\n",
    "print commentDF.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a subset of the comment DataFrame only containing the id, upvotes and body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------------+\n",
      "|     id|ups|                body|\n",
      "+-------+---+--------------------+\n",
      "|cnas8zv| 14|Most of us have s...|\n",
      "|cnas8zw|  3|But Mill's career...|\n",
      "|cnas8zx|  1|Mine uses a strai...|\n",
      "|cnas8zy|  1|           [deleted]|\n",
      "|cnas8zz|  2|Very fast, thank ...|\n",
      "|cnas900|  6|The guy is a prof...|\n",
      "|cnas901|  1|This is a great q...|\n",
      "|cnas902|  1|Is the IE-Shiv-Gh...|\n",
      "|cnas903|  1|                 :D.|\n",
      "|cnas905|  2|I don't know how ...|\n",
      "|cnas906|  2|       says you my g|\n",
      "|cnas907| 10|/r/Im14andthisisf...|\n",
      "|cnas908|  1|  i love this music!|\n",
      "|cnas909|  2|You mean the vill...|\n",
      "|cnas90a|  2|I always forget h...|\n",
      "|cnas90b|  1|           [deleted]|\n",
      "|cnas90c|  1|If you enjoy deep...|\n",
      "|cnas90d|  1|           [deleted]|\n",
      "|cnas90e|  1|Haha awesome man ...|\n",
      "|cnas90f|  3|I completely agre...|\n",
      "+-------+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentenceDF = commentDF.select('id','ups','body')\n",
    "sentenceDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the tokenizer to convert the comment bodies to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------------+--------------------+\n",
      "|     id|ups|                body|               words|\n",
      "+-------+---+--------------------+--------------------+\n",
      "|cnas8zv| 14|Most of us have s...|[most, of, us, ha...|\n",
      "|cnas8zw|  3|But Mill's career...|[but, mill's, car...|\n",
      "|cnas8zx|  1|Mine uses a strai...|[mine, uses, a, s...|\n",
      "|cnas8zy|  1|           [deleted]|         [[deleted]]|\n",
      "|cnas8zz|  2|Very fast, thank ...|[very, fast,, tha...|\n",
      "|cnas900|  6|The guy is a prof...|[the, guy, is, a,...|\n",
      "|cnas901|  1|This is a great q...|[this, is, a, gre...|\n",
      "|cnas902|  1|Is the IE-Shiv-Gh...|[is, the, ie-shiv...|\n",
      "|cnas903|  1|                 :D.|               [:d.]|\n",
      "|cnas905|  2|I don't know how ...|[i, don't, know, ...|\n",
      "|cnas906|  2|       says you my g|  [says, you, my, g]|\n",
      "|cnas907| 10|/r/Im14andthisisf...|[/r/im14andthisis...|\n",
      "|cnas908|  1|  i love this music!|[i, love, this, m...|\n",
      "|cnas909|  2|You mean the vill...|[you, mean, the, ...|\n",
      "|cnas90a|  2|I always forget h...|[i, always, forge...|\n",
      "|cnas90b|  1|           [deleted]|         [[deleted]]|\n",
      "|cnas90c|  1|If you enjoy deep...|[if, you, enjoy, ...|\n",
      "|cnas90d|  1|           [deleted]|         [[deleted]]|\n",
      "|cnas90e|  1|Haha awesome man ...|[haha, awesome, m...|\n",
      "|cnas90f|  3|I completely agre...|[i, completely, a...|\n",
      "+-------+---+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use pyspark tokenizer object to split words in array\n",
    "tokenizer = Tokenizer(inputCol=\"body\", outputCol=\"words\")\n",
    "wordsDF = tokenizer.transform(sentenceDF)\n",
    "wordsDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove stopwords from words column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use MLib library with spark to create a bag of words representation of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input data: Each row is a bag of words with a ID.\n",
    "df = spark.createDataFrame([\n",
    "    (0, \"a b c\".split(\" \")),\n",
    "    (1, \"a b b c a\".split(\" \"))\n",
    "], [\"id\", \"words\"])\n",
    "\n",
    "# fit a CountVectorizerModel from the corpus.\n",
    "cv = CountVectorizer(inputCol=\"words\", outputCol=\"features\", vocabSize=3, minDF=2.0)\n",
    "model = cv.fit(df)\n",
    "result = model.transform(df)\n",
    "result.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
