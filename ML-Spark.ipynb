{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Featurization with Spark\n",
    "\n",
    "## Imported Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json\n",
    "import time\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import * # CountVectorizer, Tokenizer, RegexTokenizer, HashingTF\n",
    "from pyspark.ml.regression import * # RandomForestRegressor, LinearRegression, DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "The timeit function will be used to measured the time it takes for functions to run. We can use this to determine the efficiency with a smaller dataset and see how this will translate to the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timeit(method):\n",
    "    '''\n",
    "    Decorator to time functions.\n",
    "    '''\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "\n",
    "        print '%r took %2.2f sec\\n' % \\\n",
    "              (method.__name__, te-ts)\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SQL example \n",
    "\n",
    "# wordsFilteredDF.createOrReplaceTempView(\"comments_table\")\n",
    "# filtered_words = sqlContext.sql(\"SELECT filtered_words FROM comments_table\")\n",
    "# filtered_words.show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "### Load data from file\n",
    "\n",
    "Initially, a portion of the 30 GB will be used to test. The data can be loaded in two ways, directly passing the filename to spark.read.json or using bz2 and reading lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timeit\n",
    "def load_data(filename, test=True, mb=1):\n",
    "    '''\n",
    "    Returns either the a DataFrame containing all the tweets or a test DataFrame containing\n",
    "    numTest comments.\n",
    "    \n",
    "    @params:\n",
    "        test - boolean, if True return test DataFrame\n",
    "        mb - the number of megabytes to load from the data set\n",
    "    '''\n",
    "    \n",
    "    # load compressed file\n",
    "    comments_file = bz2.BZ2File(filename, \"r\")\n",
    "    \n",
    "    # convert the megabytes to bytes\n",
    "    size = mb * (1024 ** 2)\n",
    "    \n",
    "    # load a test dataset of size mb\n",
    "    if test:\n",
    "        # create RDD using string returned by reading the comments file\n",
    "        # specify bytesize of file to read\n",
    "        commentRDD = sc.parallelize(comments_file.readlines(size))\n",
    "        # read RDD as json and convert to a DataFrame\n",
    "        df = spark.read.json(commentRDD)\n",
    "    # load full dataset\n",
    "    else:\n",
    "        df = spark.read.json(filename)\n",
    "    \n",
    "    # return a new DataFrame that doesn't contain deleted comments\n",
    "    return df.filter(\"body != '[deleted]'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'load_data' took 15.37 sec\n",
      "\n",
      "Snippet of Comment DataFrame:\n",
      "+-------+--------------------+---+-----+------+--------------+\n",
      "|     id|                body|ups|downs|gilded|     subreddit|\n",
      "+-------+--------------------+---+-----+------+--------------+\n",
      "|cnas8zv|Most of us have s...| 14|    0|     0|      exmormon|\n",
      "|cnas8zw|But Mill's career...|  3|    0|     0|CanadaPolitics|\n",
      "|cnas8zx|Mine uses a strai...|  1|    0|     0| AdviceAnimals|\n",
      "|cnas8zz|Very fast, thank ...|  2|    0|     0|    freedonuts|\n",
      "|cnas900|The guy is a prof...|  6|    0|     0|           WTF|\n",
      "+-------+--------------------+---+-----+------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Column names of comment DataFrame:\n",
      "['archived', 'author', 'author_flair_css_class', 'author_flair_text', 'body', 'controversiality', 'created_utc', 'distinguished', 'downs', 'edited', 'gilded', 'id', 'link_id', 'name', 'parent_id', 'retrieved_on', 'score', 'score_hidden', 'subreddit', 'subreddit_id', 'ups']\n",
      "\n",
      "The total number of comments: 1627 (deleted comments removed)\n"
     ]
    }
   ],
   "source": [
    "filename = 'RC_2015-01.bz2'\n",
    "\n",
    "# load the comments into a DataFrame\n",
    "commentDF = load_data(filename, mb=1)\n",
    "\n",
    "# Display comments and information\n",
    "print \"Snippet of Comment DataFrame:\"\n",
    "commentDF.select('id', 'body', 'ups', 'downs', 'gilded', 'subreddit').show(5)\n",
    "print \"Column names of comment DataFrame:\"\n",
    "print commentDF.columns\n",
    "print \"\\nThe total number of comments: %s (deleted comments removed)\" % commentDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a subset of the comment DataFrame only containing the id, upvotes and body. We will be performing a regression task to determine the number of upvotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------------+\n",
      "|     id|ups|                body|\n",
      "+-------+---+--------------------+\n",
      "|cnas8zv| 14|Most of us have s...|\n",
      "|cnas8zw|  3|But Mill's career...|\n",
      "|cnas8zx|  1|Mine uses a strai...|\n",
      "|cnas8zz|  2|Very fast, thank ...|\n",
      "|cnas900|  6|The guy is a prof...|\n",
      "+-------+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentenceDF = commentDF.select('id','ups','body')\n",
    "sentenceDF.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the body of the comment:\n",
    "* Use the tokenizer to convert the comment bodies to arrays\n",
    "* Remove stopwords from words column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use pyspark tokenizer object to split words in array\n",
    "pattern = \"\\\\W\"\n",
    "# tokenizer = RegexTokenizer(inputCol=\"body\", outputCol=\"words\", pattern=pattern)\n",
    "tokenizer = Tokenizer(inputCol=\"body\", outputCol=\"words\")\n",
    "wordsDF = tokenizer.transform(sentenceDF)\n",
    "\n",
    "# Remove stop words\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "wordsFilteredDF = remover.transform(wordsDF)\n",
    "\n",
    "# Remove body and words since they will no longer be used\n",
    "wordsFilteredDF = wordsFilteredDF.select('id','ups','filtered_words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be comparing two methods of featurization, CountVectorizer and HashingTF. CountVectorizer will create a bag of words representation of the words found in the body of the comment. HashingTF is a Feature Hasher and will also create a bag of words representation but will place similar words into the same bucket to limit the size of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@timeit\n",
    "def term_frequency(df, inputCol, outputCol, hashFeatures=None):\n",
    "    '''\n",
    "    Returns a DataFrame object containing a new row with the extracted features. \n",
    "    Passing hashed=True will return a Featured Hashed matrix.\n",
    "    \n",
    "    @params:\n",
    "        df - DataFrame\n",
    "        inputCol - name of input column from DataFrame to find features\n",
    "        outputCol - name of the column to save the features\n",
    "        hashFeatures - number of features for HashingTF, if None will perform \n",
    "            CountVectorization\n",
    "    '''\n",
    "    \n",
    "    # since the number of features was not passed perform standard CountVectorization\n",
    "    if hashFeatures is None:\n",
    "        cv = CountVectorizer(inputCol=inputCol, outputCol=outputCol)\n",
    "        feature_extractor = cv.fit(wordsFilteredDF)\n",
    "    # otherwise perform a feature extractor with \n",
    "    else:\n",
    "        feature_extractor = HashingTF(\\\n",
    "                              inputCol=inputCol, outputCol=outputCol, numFeatures=hashFeatures)\n",
    "    \n",
    "    # create a new DataFrame using either feature extraction method\n",
    "    return feature_extractor.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'term_frequency' took 2.47 sec\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|      filtered_words|            features|\n",
      "+--------------------+--------------------+\n",
      "|[us, family, memb...|(13306,[2,94,169,...|\n",
      "|[mill's, career, ...|(13306,[37,476,51...|\n",
      "|[mine, uses, stra...|(13306,[0,4,13,26...|\n",
      "|[fast,, thank, you!]|(13306,[95,574,13...|\n",
      "|[guy, professiona...|(13306,[18,152,38...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the occurence of each word in the comment content\n",
    "cvDF = term_frequency(\\\n",
    "    df=wordsFilteredDF, inputCol=\"filtered_words\", outputCol=\"features\")\n",
    "\n",
    "# Display snippet of new DataFrame\n",
    "cvDF.select('filtered_words','features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'term_frequency' took 0.10 sec\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|      filtered_words|            features|\n",
      "+--------------------+--------------------+\n",
      "|[us, family, memb...|(1024,[368,386,45...|\n",
      "|[mill's, career, ...|(1024,[102,211,22...|\n",
      "|[mine, uses, stra...|(1024,[112,120,18...|\n",
      "|[fast,, thank, you!]|(1024,[206,220,36...|\n",
      "|[guy, professiona...|(1024,[95,358,366...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Feature Hash the comment content\n",
    "# number of features for Feature Hash matrix, reccomended too use power of 2\n",
    "hashDF = term_frequency(\\\n",
    "    df=wordsFilteredDF, inputCol=\"filtered_words\", outputCol=\"features\", hashFeatures=1024)\n",
    "\n",
    "# Display snippet of new DataFrame\n",
    "hashDF.select('filtered_words','features').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Machine Learning\n",
    "\n",
    "### Regression: Term Frequency vs. Feature Hashing\n",
    "\n",
    "In this first example we will be comparing the computation time and accuracy of training a Random Forest Regressor. The expected result is compareable accuracry but the Feature Hashed matrix will be much more efficient.\n",
    "\n",
    "First we will create a function that will return the predicted DataFrame with the timeit decorator to keep track of run time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@timeit\n",
    "def random_forest_regression(df, featuresCol, labelCol):\n",
    "    '''\n",
    "    Returns a DataFrame containing a column of predicted values of the labelCol.\n",
    "    Predict the output of labelCol using values in featuresCol y = rf(x).\n",
    "    \n",
    "    @params:\n",
    "        df - DataFrame\n",
    "        featuresCol - input features, x\n",
    "        labelCol - output variable, y\n",
    "    '''\n",
    "    # split the training and test data using the holdout method\n",
    "    (trainingData, testData) = df.randomSplit([0.8, 0.2])\n",
    "    \n",
    "    # create the random forest regressor, limit number of trees to ten\n",
    "    dtr = RandomForestRegressor(\\\n",
    "       featuresCol=featuresCol, labelCol=labelCol)\n",
    "    \n",
    "    # fit the training data to the regressor to create the model\n",
    "    model = dtr.fit(trainingData)\n",
    "    \n",
    "    # create a DataFrame contained a column with predicted values of the labelCol\n",
    "    predictions = model.transform(testData)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then using the Feature Hashed DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'random_forest_regression' took 7.46 sec\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 6.54565\n"
     ]
    }
   ],
   "source": [
    "# train random forest regression\n",
    "predictions = random_forest_regression(df=hashDF,featuresCol=\"features\",labelCol=\"ups\")\n",
    "\n",
    "# compute the error\n",
    "evaluator = RegressionEvaluator(labelCol=\"ups\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print \"Root Mean Squared Error (RMSE) on test data = %g\" % rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+--------------------+--------------------+-----------------+\n",
      "|     id|ups|      filtered_words|            features|       prediction|\n",
      "+-------+---+--------------------+--------------------+-----------------+\n",
      "|cnas8zv| 14|[us, family, memb...|(13306,[2,94,169,...|2.846309230468395|\n",
      "|cnas8zz|  2|[fast,, thank, you!]|(13306,[95,574,13...|2.846309230468395|\n",
      "|cnas908|  1|      [love, music!]|(13306,[78,9501],...|2.846309230468395|\n",
      "|cnas90l|  2|[roofers,, people...|(13306,[16,370,50...|2.846309230468395|\n",
      "|cnas90o|  1|[agreed!, get, it...|(13306,[4,7,2347,...|2.846309230468395|\n",
      "|cnas911|  1|[don't, know, 100...|(13306,[6,10,15,2...|2.846309230468395|\n",
      "|cnas912|  3|[i'll, try, find,...|(13306,[18,90,96,...|2.846309230468395|\n",
      "|cnas916|  0|[wish, google, dr...|(13306,[335,573,5...|2.846309230468395|\n",
      "|cnas917|  2|[[](/hellohuman)m...|(13306,[102,3059,...|2.846309230468395|\n",
      "|cnas918|  3|[haha, guilty., i...|(13306,[2,16,23,2...|2.846309230468395|\n",
      "+-------+---+--------------------+--------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First using the CountVectorized DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'random_forest_regression' took 27.53 sec\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 7.04472\n"
     ]
    }
   ],
   "source": [
    "# train random forest regression\n",
    "predictions = random_forest_regression(df=cvDF,featuresCol=\"features\",labelCol=\"ups\")\n",
    "\n",
    "# compute the error\n",
    "evaluator = RegressionEvaluator(labelCol=\"ups\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print \"Root Mean Squared Error (RMSE) on test data = %g\" % rmse"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
